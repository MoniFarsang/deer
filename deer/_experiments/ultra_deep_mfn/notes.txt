**2: python train.py --version 2 --lr 1e-2 [successful]
3: python train.py --version 3 --lr 1e-2 --model mfnsinelong --dtype float64
4: python train.py --version 4 --lr 1e-2 --model mfnsine2 --dtype float64
5: python train.py --version 5 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 100000 (using skip) [vslow and the loss is vbig]
6: python train.py --version 6 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 100000 (linear weight=2.0) [similar to 3]
7: python train.py --version 7 --lr 1e-2 --model sirenlong --dtype float64 --batch_size 100000 [vvbig loss]
8: python train.py --version 8 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 100000 (10x input scale)
9: python train.py --version 9 --lr 1e-2 --model sirenlong --dtype float64 --batch_size 100000 (with log_sigmoid activation) [stuck like 3]
10: python train.py --version 10 --lr 1e-2 --model sirenlong --dtype float64 --batch_size 100000 (with log_sigmoid activation + skip) [nan]
*11: python train.py --version 11 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 100000 (4 hiddens) [better, but still stuck]
*12: python train.py --version 12 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 50000 (4 hiddens, lin from all zs) [much better than 11]
13: python train.py --version 13 --lr 1e-2 --model mfngaborlong --dtype float64 --batch_size 50000 [similar to 12]
14: python train.py --version 14 --lr 1e-2 --model mfnsinelong --dtype float64 --batch_size 10000 (8 hiddens) [similar to 12]
15: python train.py --version 15 --lr 1e-2 --model sirenlong --dtype float64 --batch_size 10000 (1000 max_evals) [stuck like 3]
